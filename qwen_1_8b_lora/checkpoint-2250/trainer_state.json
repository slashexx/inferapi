{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.8661654135338344,
  "eval_steps": 500,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017185821697099892,
      "grad_norm": 16.12008285522461,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 11.2552,
      "step": 10
    },
    {
      "epoch": 0.034371643394199784,
      "grad_norm": 17.227231979370117,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 11.2977,
      "step": 20
    },
    {
      "epoch": 0.05155746509129968,
      "grad_norm": 16.950841903686523,
      "learning_rate": 5.8e-06,
      "loss": 11.1646,
      "step": 30
    },
    {
      "epoch": 0.06874328678839957,
      "grad_norm": 18.485912322998047,
      "learning_rate": 7.800000000000002e-06,
      "loss": 10.5476,
      "step": 40
    },
    {
      "epoch": 0.08592910848549946,
      "grad_norm": 20.588258743286133,
      "learning_rate": 9.800000000000001e-06,
      "loss": 9.7279,
      "step": 50
    },
    {
      "epoch": 0.10311493018259936,
      "grad_norm": 25.071393966674805,
      "learning_rate": 1.18e-05,
      "loss": 8.5585,
      "step": 60
    },
    {
      "epoch": 0.12030075187969924,
      "grad_norm": 30.88983154296875,
      "learning_rate": 1.38e-05,
      "loss": 6.9146,
      "step": 70
    },
    {
      "epoch": 0.13748657357679914,
      "grad_norm": 31.997411727905273,
      "learning_rate": 1.58e-05,
      "loss": 4.2884,
      "step": 80
    },
    {
      "epoch": 0.15467239527389903,
      "grad_norm": 6.057561874389648,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 1.3713,
      "step": 90
    },
    {
      "epoch": 0.17185821697099893,
      "grad_norm": 0.19824224710464478,
      "learning_rate": 1.98e-05,
      "loss": 0.4902,
      "step": 100
    },
    {
      "epoch": 0.18904403866809882,
      "grad_norm": 0.16403479874134064,
      "learning_rate": 1.9999194772558114e-05,
      "loss": 0.4589,
      "step": 110
    },
    {
      "epoch": 0.20622986036519872,
      "grad_norm": 0.12025019526481628,
      "learning_rate": 1.9996411436776738e-05,
      "loss": 0.4426,
      "step": 120
    },
    {
      "epoch": 0.22341568206229862,
      "grad_norm": 0.11275415122509003,
      "learning_rate": 1.999164060483008e-05,
      "loss": 0.438,
      "step": 130
    },
    {
      "epoch": 0.24060150375939848,
      "grad_norm": 0.11978790909051895,
      "learning_rate": 1.998488322525955e-05,
      "loss": 0.4365,
      "step": 140
    },
    {
      "epoch": 0.2577873254564984,
      "grad_norm": 0.1292276382446289,
      "learning_rate": 1.9976140641573877e-05,
      "loss": 0.449,
      "step": 150
    },
    {
      "epoch": 0.2749731471535983,
      "grad_norm": 0.13135668635368347,
      "learning_rate": 1.9965414591981974e-05,
      "loss": 0.4434,
      "step": 160
    },
    {
      "epoch": 0.2921589688506982,
      "grad_norm": 0.15026484429836273,
      "learning_rate": 1.995270720904738e-05,
      "loss": 0.4156,
      "step": 170
    },
    {
      "epoch": 0.30934479054779807,
      "grad_norm": 0.14530985057353973,
      "learning_rate": 1.993802101926422e-05,
      "loss": 0.4347,
      "step": 180
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 0.14136143028736115,
      "learning_rate": 1.9921358942554917e-05,
      "loss": 0.4212,
      "step": 190
    },
    {
      "epoch": 0.34371643394199786,
      "grad_norm": 0.14309629797935486,
      "learning_rate": 1.9902724291689637e-05,
      "loss": 0.4281,
      "step": 200
    },
    {
      "epoch": 0.3609022556390977,
      "grad_norm": 0.16309916973114014,
      "learning_rate": 1.9882120771627637e-05,
      "loss": 0.4269,
      "step": 210
    },
    {
      "epoch": 0.37808807733619765,
      "grad_norm": 0.16280357539653778,
      "learning_rate": 1.9859552478780658e-05,
      "loss": 0.4057,
      "step": 220
    },
    {
      "epoch": 0.3952738990332975,
      "grad_norm": 0.15685823559761047,
      "learning_rate": 1.9835023900198456e-05,
      "loss": 0.4054,
      "step": 230
    },
    {
      "epoch": 0.41245972073039744,
      "grad_norm": 0.16210517287254333,
      "learning_rate": 1.9808539912676678e-05,
      "loss": 0.4143,
      "step": 240
    },
    {
      "epoch": 0.4296455424274973,
      "grad_norm": 0.19379734992980957,
      "learning_rate": 1.978010578178728e-05,
      "loss": 0.4026,
      "step": 250
    },
    {
      "epoch": 0.44683136412459723,
      "grad_norm": 0.15920387208461761,
      "learning_rate": 1.9749727160831593e-05,
      "loss": 0.41,
      "step": 260
    },
    {
      "epoch": 0.4640171858216971,
      "grad_norm": 0.1419166624546051,
      "learning_rate": 1.971741008971634e-05,
      "loss": 0.387,
      "step": 270
    },
    {
      "epoch": 0.48120300751879697,
      "grad_norm": 0.15241371095180511,
      "learning_rate": 1.968316099375278e-05,
      "loss": 0.3871,
      "step": 280
    },
    {
      "epoch": 0.4983888292158969,
      "grad_norm": 0.15063832700252533,
      "learning_rate": 1.9646986682379207e-05,
      "loss": 0.4178,
      "step": 290
    },
    {
      "epoch": 0.5155746509129968,
      "grad_norm": 0.16022755205631256,
      "learning_rate": 1.9608894347807112e-05,
      "loss": 0.407,
      "step": 300
    },
    {
      "epoch": 0.5327604726100966,
      "grad_norm": 0.18039008975028992,
      "learning_rate": 1.9568891563591193e-05,
      "loss": 0.3928,
      "step": 310
    },
    {
      "epoch": 0.5499462943071965,
      "grad_norm": 0.17213033139705658,
      "learning_rate": 1.9526986283123605e-05,
      "loss": 0.4054,
      "step": 320
    },
    {
      "epoch": 0.5671321160042965,
      "grad_norm": 0.17695242166519165,
      "learning_rate": 1.948318683805263e-05,
      "loss": 0.3822,
      "step": 330
    },
    {
      "epoch": 0.5843179377013964,
      "grad_norm": 0.16470468044281006,
      "learning_rate": 1.9437501936626198e-05,
      "loss": 0.4146,
      "step": 340
    },
    {
      "epoch": 0.6015037593984962,
      "grad_norm": 0.1652834266424179,
      "learning_rate": 1.9389940661960478e-05,
      "loss": 0.3789,
      "step": 350
    },
    {
      "epoch": 0.6186895810955961,
      "grad_norm": 0.16974817216396332,
      "learning_rate": 1.934051247023398e-05,
      "loss": 0.3888,
      "step": 360
    },
    {
      "epoch": 0.635875402792696,
      "grad_norm": 0.1599114090204239,
      "learning_rate": 1.9289227188807468e-05,
      "loss": 0.3898,
      "step": 370
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.17967188358306885,
      "learning_rate": 1.9236095014270066e-05,
      "loss": 0.3876,
      "step": 380
    },
    {
      "epoch": 0.6702470461868958,
      "grad_norm": 0.1862887442111969,
      "learning_rate": 1.9181126510411974e-05,
      "loss": 0.3898,
      "step": 390
    },
    {
      "epoch": 0.6874328678839957,
      "grad_norm": 0.18805184960365295,
      "learning_rate": 1.9124332606124153e-05,
      "loss": 0.3947,
      "step": 400
    },
    {
      "epoch": 0.7046186895810956,
      "grad_norm": 0.18937939405441284,
      "learning_rate": 1.906572459322545e-05,
      "loss": 0.3782,
      "step": 410
    },
    {
      "epoch": 0.7218045112781954,
      "grad_norm": 0.16983146965503693,
      "learning_rate": 1.900531412421752e-05,
      "loss": 0.397,
      "step": 420
    },
    {
      "epoch": 0.7389903329752954,
      "grad_norm": 0.18010860681533813,
      "learning_rate": 1.8943113209968094e-05,
      "loss": 0.3913,
      "step": 430
    },
    {
      "epoch": 0.7561761546723953,
      "grad_norm": 0.1777283400297165,
      "learning_rate": 1.887913421732294e-05,
      "loss": 0.3918,
      "step": 440
    },
    {
      "epoch": 0.7733619763694952,
      "grad_norm": 0.189134418964386,
      "learning_rate": 1.8813389866647108e-05,
      "loss": 0.3934,
      "step": 450
    },
    {
      "epoch": 0.790547798066595,
      "grad_norm": 0.23310798406600952,
      "learning_rate": 1.8745893229295814e-05,
      "loss": 0.3916,
      "step": 460
    },
    {
      "epoch": 0.807733619763695,
      "grad_norm": 0.19648969173431396,
      "learning_rate": 1.8676657725015608e-05,
      "loss": 0.3842,
      "step": 470
    },
    {
      "epoch": 0.8249194414607949,
      "grad_norm": 0.18903499841690063,
      "learning_rate": 1.860569711927624e-05,
      "loss": 0.3833,
      "step": 480
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.21159596741199493,
      "learning_rate": 1.8533025520533807e-05,
      "loss": 0.3958,
      "step": 490
    },
    {
      "epoch": 0.8592910848549946,
      "grad_norm": 0.1948225051164627,
      "learning_rate": 1.845865737742567e-05,
      "loss": 0.385,
      "step": 500
    },
    {
      "epoch": 0.8764769065520945,
      "grad_norm": 0.19997917115688324,
      "learning_rate": 1.8382607475897786e-05,
      "loss": 0.3869,
      "step": 510
    },
    {
      "epoch": 0.8936627282491945,
      "grad_norm": 0.2043129950761795,
      "learning_rate": 1.830489093626494e-05,
      "loss": 0.3996,
      "step": 520
    },
    {
      "epoch": 0.9108485499462943,
      "grad_norm": 0.1955508142709732,
      "learning_rate": 1.822552321020451e-05,
      "loss": 0.3851,
      "step": 530
    },
    {
      "epoch": 0.9280343716433942,
      "grad_norm": 0.2229073941707611,
      "learning_rate": 1.814452007768437e-05,
      "loss": 0.3799,
      "step": 540
    },
    {
      "epoch": 0.9452201933404941,
      "grad_norm": 0.20593443512916565,
      "learning_rate": 1.8061897643825453e-05,
      "loss": 0.3963,
      "step": 550
    },
    {
      "epoch": 0.9624060150375939,
      "grad_norm": 0.1890336573123932,
      "learning_rate": 1.7977672335699776e-05,
      "loss": 0.3857,
      "step": 560
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 0.23561301827430725,
      "learning_rate": 1.7891860899064343e-05,
      "loss": 0.39,
      "step": 570
    },
    {
      "epoch": 0.9967776584317938,
      "grad_norm": 0.18584969639778137,
      "learning_rate": 1.780448039503178e-05,
      "loss": 0.3824,
      "step": 580
    },
    {
      "epoch": 1.01374865735768,
      "grad_norm": 0.20768186450004578,
      "learning_rate": 1.771554819667818e-05,
      "loss": 0.3732,
      "step": 590
    },
    {
      "epoch": 1.0309344790547799,
      "grad_norm": 0.21426716446876526,
      "learning_rate": 1.7625081985589018e-05,
      "loss": 0.3749,
      "step": 600
    },
    {
      "epoch": 1.0481203007518798,
      "grad_norm": 0.2390541285276413,
      "learning_rate": 1.753309974834365e-05,
      "loss": 0.3841,
      "step": 610
    },
    {
      "epoch": 1.0653061224489795,
      "grad_norm": 0.2158038169145584,
      "learning_rate": 1.7439619772939228e-05,
      "loss": 0.3856,
      "step": 620
    },
    {
      "epoch": 1.0824919441460794,
      "grad_norm": 0.22262397408485413,
      "learning_rate": 1.7344660645154636e-05,
      "loss": 0.4109,
      "step": 630
    },
    {
      "epoch": 1.0996777658431793,
      "grad_norm": 0.21410046517848969,
      "learning_rate": 1.7248241244855264e-05,
      "loss": 0.3883,
      "step": 640
    },
    {
      "epoch": 1.1168635875402793,
      "grad_norm": 0.21175658702850342,
      "learning_rate": 1.7150380742239294e-05,
      "loss": 0.391,
      "step": 650
    },
    {
      "epoch": 1.1340494092373792,
      "grad_norm": 0.21850818395614624,
      "learning_rate": 1.7051098594026267e-05,
      "loss": 0.3901,
      "step": 660
    },
    {
      "epoch": 1.151235230934479,
      "grad_norm": 0.27521464228630066,
      "learning_rate": 1.695041453958866e-05,
      "loss": 0.3896,
      "step": 670
    },
    {
      "epoch": 1.168421052631579,
      "grad_norm": 0.2207384705543518,
      "learning_rate": 1.6848348597027308e-05,
      "loss": 0.3876,
      "step": 680
    },
    {
      "epoch": 1.1856068743286787,
      "grad_norm": 0.2477445751428604,
      "learning_rate": 1.6744921059191378e-05,
      "loss": 0.3745,
      "step": 690
    },
    {
      "epoch": 1.2027926960257787,
      "grad_norm": 0.24469220638275146,
      "learning_rate": 1.6640152489643705e-05,
      "loss": 0.3867,
      "step": 700
    },
    {
      "epoch": 1.2199785177228786,
      "grad_norm": 0.24567770957946777,
      "learning_rate": 1.653406371857237e-05,
      "loss": 0.3813,
      "step": 710
    },
    {
      "epoch": 1.2371643394199785,
      "grad_norm": 0.2305523157119751,
      "learning_rate": 1.6426675838649172e-05,
      "loss": 0.3715,
      "step": 720
    },
    {
      "epoch": 1.2543501611170784,
      "grad_norm": 0.24099761247634888,
      "learning_rate": 1.6318010200835994e-05,
      "loss": 0.3776,
      "step": 730
    },
    {
      "epoch": 1.2715359828141783,
      "grad_norm": 0.23959214985370636,
      "learning_rate": 1.6208088410139772e-05,
      "loss": 0.3771,
      "step": 740
    },
    {
      "epoch": 1.2887218045112783,
      "grad_norm": 0.24133740365505219,
      "learning_rate": 1.609693232131698e-05,
      "loss": 0.3757,
      "step": 750
    },
    {
      "epoch": 1.305907626208378,
      "grad_norm": 0.26538941264152527,
      "learning_rate": 1.598456403452842e-05,
      "loss": 0.373,
      "step": 760
    },
    {
      "epoch": 1.3230934479054781,
      "grad_norm": 0.23871304094791412,
      "learning_rate": 1.5871005890945278e-05,
      "loss": 0.3582,
      "step": 770
    },
    {
      "epoch": 1.3402792696025778,
      "grad_norm": 0.23449194431304932,
      "learning_rate": 1.575628046830721e-05,
      "loss": 0.3715,
      "step": 780
    },
    {
      "epoch": 1.3574650912996777,
      "grad_norm": 0.2345794141292572,
      "learning_rate": 1.5640410576433416e-05,
      "loss": 0.3699,
      "step": 790
    },
    {
      "epoch": 1.3746509129967777,
      "grad_norm": 0.24912326037883759,
      "learning_rate": 1.5523419252687573e-05,
      "loss": 0.3747,
      "step": 800
    },
    {
      "epoch": 1.3918367346938776,
      "grad_norm": 0.23864628374576569,
      "learning_rate": 1.5405329757397535e-05,
      "loss": 0.3912,
      "step": 810
    },
    {
      "epoch": 1.4090225563909775,
      "grad_norm": 0.27151796221733093,
      "learning_rate": 1.5286165569230674e-05,
      "loss": 0.3791,
      "step": 820
    },
    {
      "epoch": 1.4262083780880772,
      "grad_norm": 0.2600760757923126,
      "learning_rate": 1.5165950380525837e-05,
      "loss": 0.3831,
      "step": 830
    },
    {
      "epoch": 1.4433941997851774,
      "grad_norm": 0.26939940452575684,
      "learning_rate": 1.5044708092582807e-05,
      "loss": 0.3831,
      "step": 840
    },
    {
      "epoch": 1.460580021482277,
      "grad_norm": 0.25863587856292725,
      "learning_rate": 1.4922462810910244e-05,
      "loss": 0.3884,
      "step": 850
    },
    {
      "epoch": 1.477765843179377,
      "grad_norm": 0.24345989525318146,
      "learning_rate": 1.479923884043297e-05,
      "loss": 0.3659,
      "step": 860
    },
    {
      "epoch": 1.494951664876477,
      "grad_norm": 0.246398463845253,
      "learning_rate": 1.467506068065967e-05,
      "loss": 0.3943,
      "step": 870
    },
    {
      "epoch": 1.5121374865735768,
      "grad_norm": 0.27451926469802856,
      "learning_rate": 1.4549953020811867e-05,
      "loss": 0.3909,
      "step": 880
    },
    {
      "epoch": 1.5293233082706768,
      "grad_norm": 0.274076372385025,
      "learning_rate": 1.442394073491518e-05,
      "loss": 0.3801,
      "step": 890
    },
    {
      "epoch": 1.5465091299677765,
      "grad_norm": 0.2673019468784332,
      "learning_rate": 1.4297048876853852e-05,
      "loss": 0.3818,
      "step": 900
    },
    {
      "epoch": 1.5636949516648766,
      "grad_norm": 0.2479442059993744,
      "learning_rate": 1.4169302675389515e-05,
      "loss": 0.3571,
      "step": 910
    },
    {
      "epoch": 1.5808807733619763,
      "grad_norm": 0.25463446974754333,
      "learning_rate": 1.4040727529145182e-05,
      "loss": 0.3706,
      "step": 920
    },
    {
      "epoch": 1.5980665950590762,
      "grad_norm": 0.2565871477127075,
      "learning_rate": 1.3911349001555458e-05,
      "loss": 0.3785,
      "step": 930
    },
    {
      "epoch": 1.6152524167561761,
      "grad_norm": 0.25515249371528625,
      "learning_rate": 1.3781192815784014e-05,
      "loss": 0.3634,
      "step": 940
    },
    {
      "epoch": 1.632438238453276,
      "grad_norm": 0.2549270987510681,
      "learning_rate": 1.3650284849609264e-05,
      "loss": 0.3895,
      "step": 950
    },
    {
      "epoch": 1.649624060150376,
      "grad_norm": 0.2709490954875946,
      "learning_rate": 1.3518651130279326e-05,
      "loss": 0.3848,
      "step": 960
    },
    {
      "epoch": 1.6668098818474757,
      "grad_norm": 0.2609323263168335,
      "learning_rate": 1.3386317829337263e-05,
      "loss": 0.3744,
      "step": 970
    },
    {
      "epoch": 1.6839957035445758,
      "grad_norm": 0.28345543146133423,
      "learning_rate": 1.3253311257417632e-05,
      "loss": 0.3982,
      "step": 980
    },
    {
      "epoch": 1.7011815252416755,
      "grad_norm": 0.27751848101615906,
      "learning_rate": 1.3119657859015368e-05,
      "loss": 0.3592,
      "step": 990
    },
    {
      "epoch": 1.7183673469387755,
      "grad_norm": 0.27929362654685974,
      "learning_rate": 1.2985384207228078e-05,
      "loss": 0.3691,
      "step": 1000
    },
    {
      "epoch": 1.7355531686358754,
      "grad_norm": 0.2814277112483978,
      "learning_rate": 1.2850516998472742e-05,
      "loss": 0.3795,
      "step": 1010
    },
    {
      "epoch": 1.7527389903329753,
      "grad_norm": 0.2656020224094391,
      "learning_rate": 1.271508304717791e-05,
      "loss": 0.3866,
      "step": 1020
    },
    {
      "epoch": 1.7699248120300752,
      "grad_norm": 0.27069994807243347,
      "learning_rate": 1.2579109280452427e-05,
      "loss": 0.394,
      "step": 1030
    },
    {
      "epoch": 1.787110633727175,
      "grad_norm": 0.3065405488014221,
      "learning_rate": 1.2442622732731765e-05,
      "loss": 0.3781,
      "step": 1040
    },
    {
      "epoch": 1.804296455424275,
      "grad_norm": 0.273943692445755,
      "learning_rate": 1.2305650540403019e-05,
      "loss": 0.3648,
      "step": 1050
    },
    {
      "epoch": 1.8214822771213748,
      "grad_norm": 0.28883299231529236,
      "learning_rate": 1.2168219936409594e-05,
      "loss": 0.3647,
      "step": 1060
    },
    {
      "epoch": 1.8386680988184747,
      "grad_norm": 0.26445654034614563,
      "learning_rate": 1.2030358244836751e-05,
      "loss": 0.3591,
      "step": 1070
    },
    {
      "epoch": 1.8558539205155746,
      "grad_norm": 0.2703906297683716,
      "learning_rate": 1.189209287547901e-05,
      "loss": 0.368,
      "step": 1080
    },
    {
      "epoch": 1.8730397422126746,
      "grad_norm": 0.29142332077026367,
      "learning_rate": 1.1753451318390486e-05,
      "loss": 0.3702,
      "step": 1090
    },
    {
      "epoch": 1.8902255639097745,
      "grad_norm": 0.27819037437438965,
      "learning_rate": 1.1614461138419304e-05,
      "loss": 0.3772,
      "step": 1100
    },
    {
      "epoch": 1.9074113856068742,
      "grad_norm": 0.2707604467868805,
      "learning_rate": 1.147514996972713e-05,
      "loss": 0.3595,
      "step": 1110
    },
    {
      "epoch": 1.9245972073039743,
      "grad_norm": 0.2996300458908081,
      "learning_rate": 1.133554551029492e-05,
      "loss": 0.3706,
      "step": 1120
    },
    {
      "epoch": 1.941783029001074,
      "grad_norm": 0.2848576009273529,
      "learning_rate": 1.1195675516415961e-05,
      "loss": 0.3666,
      "step": 1130
    },
    {
      "epoch": 1.9589688506981742,
      "grad_norm": 0.2720923125743866,
      "learning_rate": 1.1055567797177375e-05,
      "loss": 0.3708,
      "step": 1140
    },
    {
      "epoch": 1.9761546723952739,
      "grad_norm": 0.29359859228134155,
      "learning_rate": 1.0915250208931065e-05,
      "loss": 0.3798,
      "step": 1150
    },
    {
      "epoch": 1.9933404940923738,
      "grad_norm": 0.3031173348426819,
      "learning_rate": 1.077475064975528e-05,
      "loss": 0.3628,
      "step": 1160
    },
    {
      "epoch": 2.0103114930182597,
      "grad_norm": 0.28381451964378357,
      "learning_rate": 1.0634097053907917e-05,
      "loss": 0.3645,
      "step": 1170
    },
    {
      "epoch": 2.02749731471536,
      "grad_norm": 0.2842406928539276,
      "learning_rate": 1.0493317386272592e-05,
      "loss": 0.3577,
      "step": 1180
    },
    {
      "epoch": 2.0446831364124596,
      "grad_norm": 0.30498018860816956,
      "learning_rate": 1.0352439636798632e-05,
      "loss": 0.3701,
      "step": 1190
    },
    {
      "epoch": 2.0618689581095597,
      "grad_norm": 0.30593159794807434,
      "learning_rate": 1.0211491814936088e-05,
      "loss": 0.3767,
      "step": 1200
    },
    {
      "epoch": 2.0790547798066594,
      "grad_norm": 0.28485018014907837,
      "learning_rate": 1.0070501944066876e-05,
      "loss": 0.3731,
      "step": 1210
    },
    {
      "epoch": 2.0962406015037596,
      "grad_norm": 0.3151817321777344,
      "learning_rate": 9.929498055933126e-06,
      "loss": 0.3668,
      "step": 1220
    },
    {
      "epoch": 2.1134264232008593,
      "grad_norm": 0.32115012407302856,
      "learning_rate": 9.788508185063915e-06,
      "loss": 0.3678,
      "step": 1230
    },
    {
      "epoch": 2.130612244897959,
      "grad_norm": 0.29166197776794434,
      "learning_rate": 9.647560363201371e-06,
      "loss": 0.3693,
      "step": 1240
    },
    {
      "epoch": 2.147798066595059,
      "grad_norm": 0.30524298548698425,
      "learning_rate": 9.506682613727408e-06,
      "loss": 0.385,
      "step": 1250
    },
    {
      "epoch": 2.164983888292159,
      "grad_norm": 0.2977280914783478,
      "learning_rate": 9.365902946092085e-06,
      "loss": 0.3666,
      "step": 1260
    },
    {
      "epoch": 2.182169709989259,
      "grad_norm": 0.3186596930027008,
      "learning_rate": 9.225249350244724e-06,
      "loss": 0.3676,
      "step": 1270
    },
    {
      "epoch": 2.1993555316863587,
      "grad_norm": 0.285946786403656,
      "learning_rate": 9.084749791068937e-06,
      "loss": 0.3534,
      "step": 1280
    },
    {
      "epoch": 2.216541353383459,
      "grad_norm": 0.3054717779159546,
      "learning_rate": 8.944432202822627e-06,
      "loss": 0.3697,
      "step": 1290
    },
    {
      "epoch": 2.2337271750805585,
      "grad_norm": 0.3148189187049866,
      "learning_rate": 8.804324483584044e-06,
      "loss": 0.3616,
      "step": 1300
    },
    {
      "epoch": 2.250912996777658,
      "grad_norm": 0.2949592173099518,
      "learning_rate": 8.664454489705086e-06,
      "loss": 0.3719,
      "step": 1310
    },
    {
      "epoch": 2.2680988184747584,
      "grad_norm": 0.31315088272094727,
      "learning_rate": 8.524850030272873e-06,
      "loss": 0.372,
      "step": 1320
    },
    {
      "epoch": 2.285284640171858,
      "grad_norm": 0.3328186273574829,
      "learning_rate": 8.385538861580698e-06,
      "loss": 0.3743,
      "step": 1330
    },
    {
      "epoch": 2.302470461868958,
      "grad_norm": 0.30458614230155945,
      "learning_rate": 8.246548681609516e-06,
      "loss": 0.359,
      "step": 1340
    },
    {
      "epoch": 2.319656283566058,
      "grad_norm": 0.31919682025909424,
      "learning_rate": 8.107907124520995e-06,
      "loss": 0.3753,
      "step": 1350
    },
    {
      "epoch": 2.336842105263158,
      "grad_norm": 0.34608763456344604,
      "learning_rate": 7.96964175516325e-06,
      "loss": 0.3508,
      "step": 1360
    },
    {
      "epoch": 2.3540279269602578,
      "grad_norm": 0.3146757185459137,
      "learning_rate": 7.831780063590411e-06,
      "loss": 0.3709,
      "step": 1370
    },
    {
      "epoch": 2.3712137486573575,
      "grad_norm": 0.31150949001312256,
      "learning_rate": 7.694349459596986e-06,
      "loss": 0.3759,
      "step": 1380
    },
    {
      "epoch": 2.3883995703544576,
      "grad_norm": 0.30515870451927185,
      "learning_rate": 7.557377267268235e-06,
      "loss": 0.3598,
      "step": 1390
    },
    {
      "epoch": 2.4055853920515573,
      "grad_norm": 0.3230002820491791,
      "learning_rate": 7.420890719547576e-06,
      "loss": 0.3574,
      "step": 1400
    },
    {
      "epoch": 2.4227712137486574,
      "grad_norm": 0.3101598620414734,
      "learning_rate": 7.284916952822096e-06,
      "loss": 0.3635,
      "step": 1410
    },
    {
      "epoch": 2.439957035445757,
      "grad_norm": 0.3155227601528168,
      "learning_rate": 7.149483001527261e-06,
      "loss": 0.3654,
      "step": 1420
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.3098572790622711,
      "learning_rate": 7.014615792771924e-06,
      "loss": 0.3692,
      "step": 1430
    },
    {
      "epoch": 2.474328678839957,
      "grad_norm": 0.3114630877971649,
      "learning_rate": 6.880342140984637e-06,
      "loss": 0.3829,
      "step": 1440
    },
    {
      "epoch": 2.4915145005370567,
      "grad_norm": 0.3065683841705322,
      "learning_rate": 6.746688742582373e-06,
      "loss": 0.3921,
      "step": 1450
    },
    {
      "epoch": 2.508700322234157,
      "grad_norm": 0.36372363567352295,
      "learning_rate": 6.61368217066274e-06,
      "loss": 0.3765,
      "step": 1460
    },
    {
      "epoch": 2.525886143931257,
      "grad_norm": 0.33733347058296204,
      "learning_rate": 6.4813488697206804e-06,
      "loss": 0.3609,
      "step": 1470
    },
    {
      "epoch": 2.5430719656283567,
      "grad_norm": 0.31792813539505005,
      "learning_rate": 6.349715150390741e-06,
      "loss": 0.3612,
      "step": 1480
    },
    {
      "epoch": 2.5602577873254564,
      "grad_norm": 0.3424159288406372,
      "learning_rate": 6.2188071842159895e-06,
      "loss": 0.3731,
      "step": 1490
    },
    {
      "epoch": 2.5774436090225565,
      "grad_norm": 0.3309735655784607,
      "learning_rate": 6.088650998444548e-06,
      "loss": 0.37,
      "step": 1500
    },
    {
      "epoch": 2.5946294307196562,
      "grad_norm": 0.3424483835697174,
      "learning_rate": 5.959272470854822e-06,
      "loss": 0.3794,
      "step": 1510
    },
    {
      "epoch": 2.611815252416756,
      "grad_norm": 0.34001585841178894,
      "learning_rate": 5.830697324610488e-06,
      "loss": 0.3708,
      "step": 1520
    },
    {
      "epoch": 2.629001074113856,
      "grad_norm": 0.30594828724861145,
      "learning_rate": 5.7029511231461506e-06,
      "loss": 0.3604,
      "step": 1530
    },
    {
      "epoch": 2.6461868958109562,
      "grad_norm": 0.37737053632736206,
      "learning_rate": 5.576059265084823e-06,
      "loss": 0.3531,
      "step": 1540
    },
    {
      "epoch": 2.663372717508056,
      "grad_norm": 0.3487147390842438,
      "learning_rate": 5.450046979188136e-06,
      "loss": 0.3809,
      "step": 1550
    },
    {
      "epoch": 2.6805585392051556,
      "grad_norm": 0.33826544880867004,
      "learning_rate": 5.324939319340329e-06,
      "loss": 0.361,
      "step": 1560
    },
    {
      "epoch": 2.697744360902256,
      "grad_norm": 0.34010177850723267,
      "learning_rate": 5.200761159567035e-06,
      "loss": 0.3675,
      "step": 1570
    },
    {
      "epoch": 2.7149301825993555,
      "grad_norm": 0.35698238015174866,
      "learning_rate": 5.077537189089762e-06,
      "loss": 0.3768,
      "step": 1580
    },
    {
      "epoch": 2.732116004296455,
      "grad_norm": 0.3251749873161316,
      "learning_rate": 4.955291907417193e-06,
      "loss": 0.3659,
      "step": 1590
    },
    {
      "epoch": 2.7493018259935553,
      "grad_norm": 0.3314337134361267,
      "learning_rate": 4.8340496194741685e-06,
      "loss": 0.3599,
      "step": 1600
    },
    {
      "epoch": 2.7664876476906555,
      "grad_norm": 0.3490537405014038,
      "learning_rate": 4.71383443076933e-06,
      "loss": 0.3654,
      "step": 1610
    },
    {
      "epoch": 2.783673469387755,
      "grad_norm": 0.351118266582489,
      "learning_rate": 4.594670242602464e-06,
      "loss": 0.3721,
      "step": 1620
    },
    {
      "epoch": 2.800859291084855,
      "grad_norm": 0.34393996000289917,
      "learning_rate": 4.476580747312429e-06,
      "loss": 0.3679,
      "step": 1630
    },
    {
      "epoch": 2.818045112781955,
      "grad_norm": 0.3534909784793854,
      "learning_rate": 4.359589423566589e-06,
      "loss": 0.3618,
      "step": 1640
    },
    {
      "epoch": 2.8352309344790547,
      "grad_norm": 0.35142964124679565,
      "learning_rate": 4.2437195316927895e-06,
      "loss": 0.3683,
      "step": 1650
    },
    {
      "epoch": 2.8524167561761544,
      "grad_norm": 0.3235563635826111,
      "learning_rate": 4.128994109054724e-06,
      "loss": 0.3494,
      "step": 1660
    },
    {
      "epoch": 2.8696025778732546,
      "grad_norm": 0.3422437906265259,
      "learning_rate": 4.015435965471581e-06,
      "loss": 0.3535,
      "step": 1670
    },
    {
      "epoch": 2.8867883995703547,
      "grad_norm": 0.3540600538253784,
      "learning_rate": 3.90306767868302e-06,
      "loss": 0.3616,
      "step": 1680
    },
    {
      "epoch": 2.9039742212674544,
      "grad_norm": 0.33086076378822327,
      "learning_rate": 3.79191158986023e-06,
      "loss": 0.3541,
      "step": 1690
    },
    {
      "epoch": 2.921160042964554,
      "grad_norm": 0.34759998321533203,
      "learning_rate": 3.6819897991640106e-06,
      "loss": 0.3685,
      "step": 1700
    },
    {
      "epoch": 2.9383458646616543,
      "grad_norm": 0.32741549611091614,
      "learning_rate": 3.5733241613508296e-06,
      "loss": 0.3602,
      "step": 1710
    },
    {
      "epoch": 2.955531686358754,
      "grad_norm": 0.37615934014320374,
      "learning_rate": 3.4659362814276343e-06,
      "loss": 0.3777,
      "step": 1720
    },
    {
      "epoch": 2.9727175080558537,
      "grad_norm": 0.35607075691223145,
      "learning_rate": 3.359847510356293e-06,
      "loss": 0.38,
      "step": 1730
    },
    {
      "epoch": 2.989903329752954,
      "grad_norm": 0.3311634659767151,
      "learning_rate": 3.255078940808625e-06,
      "loss": 0.3755,
      "step": 1740
    },
    {
      "epoch": 3.00687432867884,
      "grad_norm": 0.3810318112373352,
      "learning_rate": 3.151651402972694e-06,
      "loss": 0.3572,
      "step": 1750
    },
    {
      "epoch": 3.0240601503759397,
      "grad_norm": 0.3422941565513611,
      "learning_rate": 3.0495854604113406e-06,
      "loss": 0.3648,
      "step": 1760
    },
    {
      "epoch": 3.04124597207304,
      "grad_norm": 0.32861337065696716,
      "learning_rate": 2.9489014059737353e-06,
      "loss": 0.3515,
      "step": 1770
    },
    {
      "epoch": 3.0584317937701395,
      "grad_norm": 0.3367862403392792,
      "learning_rate": 2.8496192577607098e-06,
      "loss": 0.3515,
      "step": 1780
    },
    {
      "epoch": 3.0756176154672397,
      "grad_norm": 0.3525005280971527,
      "learning_rate": 2.751758755144739e-06,
      "loss": 0.3643,
      "step": 1790
    },
    {
      "epoch": 3.0928034371643394,
      "grad_norm": 0.33194664120674133,
      "learning_rate": 2.6553393548453665e-06,
      "loss": 0.3546,
      "step": 1800
    },
    {
      "epoch": 3.1099892588614395,
      "grad_norm": 0.35603824257850647,
      "learning_rate": 2.560380227060776e-06,
      "loss": 0.3777,
      "step": 1810
    },
    {
      "epoch": 3.127175080558539,
      "grad_norm": 0.34536659717559814,
      "learning_rate": 2.466900251656349e-06,
      "loss": 0.356,
      "step": 1820
    },
    {
      "epoch": 3.144360902255639,
      "grad_norm": 0.32730236649513245,
      "learning_rate": 2.3749180144109853e-06,
      "loss": 0.3541,
      "step": 1830
    },
    {
      "epoch": 3.161546723952739,
      "grad_norm": 0.330279141664505,
      "learning_rate": 2.2844518033218256e-06,
      "loss": 0.3659,
      "step": 1840
    },
    {
      "epoch": 3.1787325456498388,
      "grad_norm": 0.3314681351184845,
      "learning_rate": 2.195519604968224e-06,
      "loss": 0.363,
      "step": 1850
    },
    {
      "epoch": 3.195918367346939,
      "grad_norm": 0.33024200797080994,
      "learning_rate": 2.1081391009356565e-06,
      "loss": 0.3867,
      "step": 1860
    },
    {
      "epoch": 3.2131041890440386,
      "grad_norm": 0.3575136363506317,
      "learning_rate": 2.02232766430023e-06,
      "loss": 0.369,
      "step": 1870
    },
    {
      "epoch": 3.2302900107411388,
      "grad_norm": 0.3550882637500763,
      "learning_rate": 1.9381023561745483e-06,
      "loss": 0.3514,
      "step": 1880
    },
    {
      "epoch": 3.2474758324382385,
      "grad_norm": 0.36655813455581665,
      "learning_rate": 1.855479922315635e-06,
      "loss": 0.3661,
      "step": 1890
    },
    {
      "epoch": 3.264661654135338,
      "grad_norm": 0.33756470680236816,
      "learning_rate": 1.7744767897954917e-06,
      "loss": 0.3808,
      "step": 1900
    },
    {
      "epoch": 3.2818474758324383,
      "grad_norm": 0.35782530903816223,
      "learning_rate": 1.695109063735063e-06,
      "loss": 0.3677,
      "step": 1910
    },
    {
      "epoch": 3.299033297529538,
      "grad_norm": 0.3531714677810669,
      "learning_rate": 1.6173925241022159e-06,
      "loss": 0.3675,
      "step": 1920
    },
    {
      "epoch": 3.316219119226638,
      "grad_norm": 0.3740413188934326,
      "learning_rate": 1.541342622574331e-06,
      "loss": 0.371,
      "step": 1930
    },
    {
      "epoch": 3.333404940923738,
      "grad_norm": 0.3501414954662323,
      "learning_rate": 1.4669744794661944e-06,
      "loss": 0.3451,
      "step": 1940
    },
    {
      "epoch": 3.350590762620838,
      "grad_norm": 0.3653887212276459,
      "learning_rate": 1.3943028807237602e-06,
      "loss": 0.369,
      "step": 1950
    },
    {
      "epoch": 3.3677765843179377,
      "grad_norm": 0.3935338258743286,
      "learning_rate": 1.323342274984395e-06,
      "loss": 0.373,
      "step": 1960
    },
    {
      "epoch": 3.3849624060150374,
      "grad_norm": 0.3486230969429016,
      "learning_rate": 1.25410677070419e-06,
      "loss": 0.381,
      "step": 1970
    },
    {
      "epoch": 3.4021482277121375,
      "grad_norm": 0.36782121658325195,
      "learning_rate": 1.1866101333528934e-06,
      "loss": 0.368,
      "step": 1980
    },
    {
      "epoch": 3.4193340494092372,
      "grad_norm": 0.3327780067920685,
      "learning_rate": 1.1208657826770575e-06,
      "loss": 0.3651,
      "step": 1990
    },
    {
      "epoch": 3.4365198711063374,
      "grad_norm": 0.3345704674720764,
      "learning_rate": 1.0568867900319079e-06,
      "loss": 0.3799,
      "step": 2000
    },
    {
      "epoch": 3.453705692803437,
      "grad_norm": 0.3173501789569855,
      "learning_rate": 9.946858757824817e-07,
      "loss": 0.3661,
      "step": 2010
    },
    {
      "epoch": 3.4708915145005372,
      "grad_norm": 0.3371313214302063,
      "learning_rate": 9.34275406774553e-07,
      "loss": 0.3519,
      "step": 2020
    },
    {
      "epoch": 3.488077336197637,
      "grad_norm": 0.3683377504348755,
      "learning_rate": 8.756673938758486e-07,
      "loss": 0.3715,
      "step": 2030
    },
    {
      "epoch": 3.5052631578947366,
      "grad_norm": 0.3610198199748993,
      "learning_rate": 8.188734895880302e-07,
      "loss": 0.3541,
      "step": 2040
    },
    {
      "epoch": 3.522448979591837,
      "grad_norm": 0.3558095097541809,
      "learning_rate": 7.639049857299386e-07,
      "loss": 0.3622,
      "step": 2050
    },
    {
      "epoch": 3.5396348012889365,
      "grad_norm": 0.3412601947784424,
      "learning_rate": 7.107728111925371e-07,
      "loss": 0.3356,
      "step": 2060
    },
    {
      "epoch": 3.5568206229860366,
      "grad_norm": 0.32795557379722595,
      "learning_rate": 6.59487529766023e-07,
      "loss": 0.3708,
      "step": 2070
    },
    {
      "epoch": 3.5740064446831363,
      "grad_norm": 0.34350723028182983,
      "learning_rate": 6.100593380395248e-07,
      "loss": 0.3742,
      "step": 2080
    },
    {
      "epoch": 3.5911922663802365,
      "grad_norm": 0.33937421441078186,
      "learning_rate": 5.624980633738031e-07,
      "loss": 0.366,
      "step": 2090
    },
    {
      "epoch": 3.608378088077336,
      "grad_norm": 0.3667924702167511,
      "learning_rate": 5.168131619473704e-07,
      "loss": 0.3572,
      "step": 2100
    },
    {
      "epoch": 3.625563909774436,
      "grad_norm": 0.3315117657184601,
      "learning_rate": 4.730137168763982e-07,
      "loss": 0.3522,
      "step": 2110
    },
    {
      "epoch": 3.642749731471536,
      "grad_norm": 0.32612740993499756,
      "learning_rate": 4.3110843640880917e-07,
      "loss": 0.3425,
      "step": 2120
    },
    {
      "epoch": 3.6599355531686357,
      "grad_norm": 0.35995787382125854,
      "learning_rate": 3.9110565219289134e-07,
      "loss": 0.3593,
      "step": 2130
    },
    {
      "epoch": 3.677121374865736,
      "grad_norm": 0.35591810941696167,
      "learning_rate": 3.530133176207939e-07,
      "loss": 0.37,
      "step": 2140
    },
    {
      "epoch": 3.6943071965628356,
      "grad_norm": 0.32592329382896423,
      "learning_rate": 3.168390062472226e-07,
      "loss": 0.3614,
      "step": 2150
    },
    {
      "epoch": 3.7114930182599357,
      "grad_norm": 0.33591875433921814,
      "learning_rate": 2.8258991028366046e-07,
      "loss": 0.3649,
      "step": 2160
    },
    {
      "epoch": 3.7286788399570354,
      "grad_norm": 0.3570389151573181,
      "learning_rate": 2.502728391684095e-07,
      "loss": 0.3468,
      "step": 2170
    },
    {
      "epoch": 3.745864661654135,
      "grad_norm": 0.33847576379776,
      "learning_rate": 2.1989421821272173e-07,
      "loss": 0.3707,
      "step": 2180
    },
    {
      "epoch": 3.7630504833512353,
      "grad_norm": 0.3987850546836853,
      "learning_rate": 1.91460087323323e-07,
      "loss": 0.3785,
      "step": 2190
    },
    {
      "epoch": 3.780236305048335,
      "grad_norm": 0.3691679835319519,
      "learning_rate": 1.6497609980154817e-07,
      "loss": 0.3677,
      "step": 2200
    },
    {
      "epoch": 3.797422126745435,
      "grad_norm": 0.3559161424636841,
      "learning_rate": 1.4044752121934236e-07,
      "loss": 0.3588,
      "step": 2210
    },
    {
      "epoch": 3.814607948442535,
      "grad_norm": 0.35266241431236267,
      "learning_rate": 1.1787922837236287e-07,
      "loss": 0.3633,
      "step": 2220
    },
    {
      "epoch": 3.831793770139635,
      "grad_norm": 0.3618597388267517,
      "learning_rate": 9.727570831036592e-08,
      "loss": 0.365,
      "step": 2230
    },
    {
      "epoch": 3.8489795918367347,
      "grad_norm": 0.32062599062919617,
      "learning_rate": 7.864105744508466e-08,
      "loss": 0.3647,
      "step": 2240
    },
    {
      "epoch": 3.8661654135338344,
      "grad_norm": 0.40082624554634094,
      "learning_rate": 6.197898073578068e-08,
      "loss": 0.3836,
      "step": 2250
    }
  ],
  "logging_steps": 10,
  "max_steps": 2328,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6900465630799462e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
